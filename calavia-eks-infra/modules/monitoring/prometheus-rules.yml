# Custom Prometheus Rules for Gaming Infrastructure
groups:
# EKS Cluster Health Rules
- name: eks.cluster.rules
  rules:
  - alert: EKSClusterDown
    expr: up{job="kubernetes-apiservers"} == 0
    for: 1m
    labels:
      severity: critical
      component: kubernetes
    annotations:
      summary: "EKS cluster API server is down"
      description: "EKS cluster {{ $labels.cluster }} API server has been down for more than 1 minute"
      runbook_url: "https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubernetesapiservererrorbudgetburn"

  - alert: EKSNodeNotReady
    expr: kube_node_status_condition{condition="Ready",status="true"} == 0
    for: 5m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "EKS node is not ready"
      description: "Node {{ $labels.node }} has been not ready for more than 5 minutes"

  - alert: EKSHighNodeCPU
    expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 90
    for: 10m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "High CPU usage on EKS node"
      description: "Node {{ $labels.instance }} has CPU usage above 90% for more than 10 minutes"

  - alert: EKSHighNodeMemory
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
    for: 10m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "High memory usage on EKS node"
      description: "Node {{ $labels.instance }} has memory usage above 90% for more than 10 minutes"

# Game Server Application Rules
- name: game.server.rules
  rules:
  - alert: GameServerPodCrashLooping
    expr: rate(kube_pod_container_status_restarts_total{namespace=~"game-.*"}[5m]) > 0
    for: 2m
    labels:
      severity: critical
      component: game-server
    annotations:
      summary: "Game server pod is crash looping"
      description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting frequently"

  - alert: GameServerHighLatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{namespace=~"game-.*"}[5m])) > 0.5
    for: 5m
    labels:
      severity: warning
      component: game-server
    annotations:
      summary: "High latency in game server"
      description: "95th percentile latency is {{ $value }}s for {{ $labels.service }} in {{ $labels.namespace }}"

  - alert: GameServerHighErrorRate
    expr: rate(http_requests_total{status=~"5..",namespace=~"game-.*"}[5m]) / rate(http_requests_total{namespace=~"game-.*"}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
      component: game-server
    annotations:
      summary: "High error rate in game server"
      description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.service }} in {{ $labels.namespace }}"

  - alert: GameServerLowThroughput
    expr: rate(http_requests_total{namespace=~"game-.*"}[5m]) < 1
    for: 10m
    labels:
      severity: warning
      component: game-server
    annotations:
      summary: "Low throughput in game server"
      description: "Request rate is {{ $value }} req/s for {{ $labels.service }} in {{ $labels.namespace }}"

# Database Rules (RDS PostgreSQL)
- name: database.rules
  rules:
  - alert: DatabaseConnectionsHigh
    expr: postgresql_max_connections - postgresql_connections > 10
    for: 5m
    labels:
      severity: warning
      component: database
      database: postgresql
    annotations:
      summary: "High number of database connections"
      description: "PostgreSQL instance {{ $labels.instance }} has {{ $value }} available connections remaining"

  - alert: DatabaseSlowQueries
    expr: rate(postgresql_slow_queries_total[5m]) > 0.1
    for: 5m
    labels:
      severity: warning
      component: database
      database: postgresql
    annotations:
      summary: "Database has slow queries"
      description: "PostgreSQL instance {{ $labels.instance }} has {{ $value }} slow queries per second"

  - alert: DatabaseReplicationLag
    expr: postgresql_replication_lag_seconds > 30
    for: 2m
    labels:
      severity: critical
      component: database
      database: postgresql
    annotations:
      summary: "High database replication lag"
      description: "PostgreSQL replication lag is {{ $value }}s on {{ $labels.instance }}"

# Redis/ElastiCache Rules
- name: redis.rules
  rules:
  - alert: RedisDown
    expr: redis_up == 0
    for: 1m
    labels:
      severity: critical
      component: cache
      database: redis
    annotations:
      summary: "Redis instance is down"
      description: "Redis instance {{ $labels.instance }} has been down for more than 1 minute"

  - alert: RedisHighMemoryUsage
    expr: (redis_memory_used_bytes / redis_memory_max_bytes) * 100 > 90
    for: 5m
    labels:
      severity: warning
      component: cache
      database: redis
    annotations:
      summary: "High Redis memory usage"
      description: "Redis instance {{ $labels.instance }} memory usage is {{ $value }}%"

  - alert: RedisHighConnections
    expr: redis_connected_clients > 1000
    for: 5m
    labels:
      severity: warning
      component: cache
      database: redis
    annotations:
      summary: "High number of Redis connections"
      description: "Redis instance {{ $labels.instance }} has {{ $value }} connected clients"

  - alert: RedisSlowLog
    expr: increase(redis_slowlog_length[5m]) > 0
    for: 1m
    labels:
      severity: warning
      component: cache
      database: redis
    annotations:
      summary: "Redis slow queries detected"
      description: "Redis instance {{ $labels.instance }} has {{ $value }} slow queries in the last 5 minutes"

# Load Balancer Rules
- name: loadbalancer.rules
  rules:
  - alert: ALBHighResponseTime
    expr: aws_alb_target_response_time_average > 2
    for: 5m
    labels:
      severity: warning
      component: loadbalancer
    annotations:
      summary: "High ALB response time"
      description: "ALB {{ $labels.load_balancer }} average response time is {{ $value }}s"

  - alert: ALBHighErrorRate
    expr: (aws_alb_http_code_target_5xx_count / aws_alb_request_count) > 0.05
    for: 5m
    labels:
      severity: critical
      component: loadbalancer
    annotations:
      summary: "High ALB error rate"
      description: "ALB {{ $labels.load_balancer }} has {{ $value | humanizePercentage }} error rate"

  - alert: ALBUnhealthyTargets
    expr: aws_alb_unhealthy_host_count > 0
    for: 2m
    labels:
      severity: critical
      component: loadbalancer
    annotations:
      summary: "ALB has unhealthy targets"
      description: "ALB {{ $labels.load_balancer }} has {{ $value }} unhealthy targets"

# Storage Rules
- name: storage.rules
  rules:
  - alert: PVCStorageUsageHigh
    expr: (kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) * 100 > 85
    for: 5m
    labels:
      severity: warning
      component: storage
    annotations:
      summary: "High PVC storage usage"
      description: "PVC {{ $labels.persistentvolumeclaim }} in namespace {{ $labels.namespace }} is {{ $value }}% full"

  - alert: PVCStorageUsageCritical
    expr: (kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) * 100 > 95
    for: 2m
    labels:
      severity: critical
      component: storage
    annotations:
      summary: "Critical PVC storage usage"
      description: "PVC {{ $labels.persistentvolumeclaim }} in namespace {{ $labels.namespace }} is {{ $value }}% full"

# Ingress Rules
- name: ingress.rules
  rules:
  - alert: IngressCertificateExpiring
    expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 7
    for: 1h
    labels:
      severity: warning
      component: ingress
    annotations:
      summary: "SSL certificate expiring soon"
      description: "SSL certificate for {{ $labels.instance }} expires in {{ $value | humanizeDuration }}"

  - alert: IngressDown
    expr: probe_success{job="blackbox"} == 0
    for: 2m
    labels:
      severity: critical
      component: ingress
    annotations:
      summary: "Ingress endpoint is down"
      description: "Ingress endpoint {{ $labels.instance }} has been down for more than 2 minutes"

# Custom Recording Rules for Game Metrics
- name: game.recording.rules
  interval: 30s
  rules:
  - record: game:active_players:rate5m
    expr: rate(game_active_players_total[5m])
  
  - record: game:match_duration:histogram_quantile
    expr: histogram_quantile(0.95, rate(game_match_duration_seconds_bucket[5m]))
  
  - record: game:server_capacity:utilization
    expr: (game_active_matches / game_server_capacity) * 100
  
  - record: game:database_query:rate5m
    expr: rate(game_database_queries_total[5m])
  
  - record: game:cache_hit:ratio5m
    expr: rate(game_cache_hits_total[5m]) / rate(game_cache_requests_total[5m])
