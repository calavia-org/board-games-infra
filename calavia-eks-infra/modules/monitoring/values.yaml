# Kube-Prometheus-Stack Helm Values
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: false
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: false
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: false
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

global:
  rbac:
    create: true

alertmanager:
  enabled: true
  alertmanagerSpec:
    retention: "{{ .Values.retention_days }}d"
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp2
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: ${alertmanager_storage}
    replicas: 1
    logFormat: logfmt
    logLevel: info
    portName: web
  
  config:
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@${cluster_name}.local'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          alertname: Watchdog
        receiver: 'null'
      - match_re:
          severity: critical|warning
        receiver: 'critical-alerts'
    
    receivers:
    - name: 'null'
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://example.com/'
    - name: 'critical-alerts'
      email_configs:
      - to: '${email_notifications}'
        subject: '[${cluster_name}] Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
%{ if slack_webhook_url != "" }
      slack_configs:
      - api_url: '${slack_webhook_url}'
        channel: '#alerts'
        title: '[${cluster_name}] Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}
%{ endif }

prometheus:
  enabled: true
  prometheusSpec:
    retention: "${retention_days}d"
    retentionSize: "45GB"
    replicas: 1
    shards: 1
    logFormat: logfmt
    logLevel: info
    scrapeInterval: 30s
    evaluationInterval: 30s
    enableAdminAPI: false
    
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp2
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: ${prometheus_storage}
    
    ruleSelector: {}
    ruleNamespaceSelector: {}
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelector: {}
    podMonitorNamespaceSelector: {}
    podMonitorSelectorNilUsesHelmValues: false
    
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m

    additionalScrapeConfigs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep  
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

grafana:
  enabled: true
  adminPassword: ${grafana_admin_password}
  
  persistence:
    enabled: true
    type: pvc
    storageClassName: gp2
    accessModes:
    - ReadWriteOnce
    size: ${grafana_storage}
  
  resources:
    requests:
      memory: 256Mi
      cpu: 100m
    limits:
      memory: 512Mi
      cpu: 200m
  
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default
  
  dashboards:
    default:
      kubernetes-cluster-monitoring:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      kubernetes-pod-monitoring:
        gnetId: 6417
        revision: 1
        datasource: Prometheus
      node-exporter:
        gnetId: 1860
        revision: 27
        datasource: Prometheus
      kubernetes-ingress:
        gnetId: 9614
        revision: 1
        datasource: Prometheus

  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://kube-prometheus-stack-prometheus:9090
        access: proxy
        isDefault: true

kubeApiServer:
  enabled: true

kubelet:
  enabled: true
  namespace: kube-system

kubeControllerManager:
  enabled: false

coreDns:
  enabled: true

kubeDns:
  enabled: false

kubeEtcd:
  enabled: false

kubeScheduler:
  enabled: false

kubeProxy:
  enabled: false

kubeStateMetrics:
  enabled: true

kube-state-metrics:
  metricLabelsAllowlist:
    - pods=[*]
    - deployments=[*]
    - persistentvolumeclaims=[*]

nodeExporter:
  enabled: true

prometheus-node-exporter:
  podLabels:
    jobLabel: node-exporter
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$

prometheusOperator:
  enabled: true
  manageCrds: true
  createCustomResource: true
